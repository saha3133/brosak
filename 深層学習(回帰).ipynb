{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "線形回帰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9BuGuNS4XpCk"
      },
      "outputs": [],
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nFqLX4N-XpCk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchviz import make_dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EWZHxbB1XpCl"
      },
      "outputs": [],
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの浮動小数点の表示精度\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "入力1出力1の線形関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lzycf0HxXpCm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=1, out_features=1, bias=True)\n"
          ]
        }
      ],
      "source": [
        "# 乱数の種固定\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 入力:1 出力:1 の線形関数の定義\n",
        "l1 = nn.Linear(1, 1)\n",
        "\n",
        "# 線形関数の表示\n",
        "print(l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pSvee2CeXpCm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name:  weight\n",
            "tensor:  Parameter containing:\n",
            "tensor([[-0.4078]], requires_grad=True)\n",
            "shape:  torch.Size([1, 1])\n",
            "name:  bias\n",
            "tensor:  Parameter containing:\n",
            "tensor([0.0331], requires_grad=True)\n",
            "shape:  torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "# パラメータ名、パラメータ値、shapeの表示\n",
        "\n",
        "for param in l1.named_parameters():\n",
        "    print('name: ', param[0])\n",
        "    print('tensor: ', param[1])\n",
        "    print('shape: ', param[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LKYmasnBXpCn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[2.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# 初期値設定\n",
        "nn.init.constant_(l1.weight, 2.0)\n",
        "nn.init.constant_(l1.bias, 1.0)\n",
        "\n",
        "# 結果確認\n",
        "print(l1.weight)\n",
        "print(l1.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UZNxp3fYXpCn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1])\n",
            "tensor([[-2.],\n",
            "        [-1.],\n",
            "        [ 0.],\n",
            "        [ 1.],\n",
            "        [ 2.]])\n"
          ]
        }
      ],
      "source": [
        "# テスト用データ生成\n",
        "\n",
        "# x_npをnumpy配列で定義\n",
        "x_np = np.arange(-2, 2.1, 1)\n",
        "\n",
        "# Tensor化\n",
        "x = torch.tensor(x_np).float()\n",
        "\n",
        "# サイズを(N,1)に変更\n",
        "x = x.view(-1,1)\n",
        "\n",
        "# 結果確認\n",
        "print(x.shape)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2De8gINFXpCo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1])\n",
            "tensor([[-3.],\n",
            "        [-1.],\n",
            "        [ 1.],\n",
            "        [ 3.],\n",
            "        [ 5.]])\n"
          ]
        }
      ],
      "source": [
        "# 1次関数のテスト\n",
        "\n",
        "y = l1(x)\n",
        "\n",
        "print(y.shape)\n",
        "print(y.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "入力2出力1の線形関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VyebhECaXpCp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1., 1.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([2.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# 入力:2 出力:1 の線形関数の定義\n",
        "l2 = nn.Linear(2, 1)\n",
        "\n",
        "# 初期値設定\n",
        "nn.init.constant_(l2.weight, 1.0)\n",
        "nn.init.constant_(l2.bias, 2.0)\n",
        "\n",
        "# 結果確認\n",
        "print(l2.weight)\n",
        "print(l2.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S1yCAOCcXpCp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 2])\n",
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# 2次元numpy配列\n",
        "x2_np = np.array([[0, 0], [0, 1], [1, 0], [1,1]])\n",
        "\n",
        "# Tensor化\n",
        "x2 =  torch.tensor(x2_np).float()\n",
        "\n",
        "# 結果確認\n",
        "print(x2.shape)\n",
        "print(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bZ3OsIWJXpCp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n",
            "tensor([[2.],\n",
            "        [3.],\n",
            "        [3.],\n",
            "        [4.]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 関数値計算\n",
        "y2 = l2(x2)\n",
        "\n",
        "# shape確認\n",
        "print(y2.shape)\n",
        "\n",
        "# 値確認\n",
        "print(y2.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "入力2出力3の線形関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o5xGgx2kXpCq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [2., 2.],\n",
            "        [3., 3.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([2., 2., 2.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# 入力:2 出力:3 の線形関数の定義\n",
        "\n",
        "l3 = nn.Linear(2, 3)\n",
        "\n",
        "# 初期値設定\n",
        "nn.init.constant_(l3.weight[0,:], 1.0)\n",
        "nn.init.constant_(l3.weight[1,:], 2.0)\n",
        "nn.init.constant_(l3.weight[2,:], 3.0)\n",
        "nn.init.constant_(l3.bias, 2.0)\n",
        "\n",
        "# 結果確認\n",
        "print(l3.weight)\n",
        "print(l3.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rL6qApqTXpCq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3])\n",
            "tensor([[2., 2., 2.],\n",
            "        [3., 4., 5.],\n",
            "        [3., 4., 5.],\n",
            "        [4., 6., 8.]])\n"
          ]
        }
      ],
      "source": [
        "# 関数値計算\n",
        "y3 = l3(x2)\n",
        "\n",
        "# shape確認\n",
        "print(y3.shape)\n",
        "\n",
        "# 値確認\n",
        "print(y3.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "カスタムクラスを利用したモデル定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3bcQHUdyXpCt"
      },
      "outputs": [],
      "source": [
        "# モデルのクラス定義\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        #  親クラスnn.Modulesの初期化呼び出し\n",
        "        super().__init__()\n",
        "\n",
        "        # 出力層の定義\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "\n",
        "    # 予測関数の定義\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x) # 線形回帰\n",
        "        return x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5FLHS8bvXpCt"
      },
      "outputs": [],
      "source": [
        "# ダミー入力\n",
        "inputs = torch.ones(100,1)\n",
        "\n",
        "# インスタンスの生成 (１入力1出力の線形モデル)\n",
        "n_input = 1\n",
        "n_output = 1\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 予測\n",
        "outputs = net(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "データ準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wva-PxPSJzyg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "C:\\Users\\sakurai\\AppData\\Local\\Temp\\ipykernel_32888\\3017576456.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  raw_df = pd.read_csv(data_url, sep=\"\\s+\",\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "元データ (506, 13) (506,)\n",
            "項目名:  ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n"
          ]
        }
      ],
      "source": [
        "# 学習用データ準備\n",
        "\n",
        "# 「ボストン・データセット」はscikit-learnのライブラリでも取得できるが、\n",
        "# その場合、将来版で利用できなくなる予定のため、別Webサイトから取得する\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\",\n",
        "    skiprows=22, header=None)\n",
        "x_org = np.hstack([raw_df.values[::2, :],\n",
        "    raw_df.values[1::2, :2]])\n",
        "yt = raw_df.values[1::2, 2]\n",
        "feature_names = np.array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX',\n",
        "    'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT'])\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_org.shape, yt.shape)\n",
        "print('項目名: ', feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ro0A3LlSXpCs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "絞り込み後 (506, 1)\n",
            "[[6.575]\n",
            " [6.421]\n",
            " [7.185]\n",
            " [6.998]\n",
            " [7.147]]\n",
            "正解データ\n",
            "[24.  21.6 34.7 33.4 36.2]\n"
          ]
        }
      ],
      "source": [
        "# データ絞り込み (項目 RMのみ)\n",
        "#x = x_org[:,feature_names == 'RM']\n",
        "rm_index = np.where(feature_names == 'RM')[0][0]  # [0]で配列を取得し、[0]で値を抽出\n",
        "x = x_org[:, [rm_index]]  # 2次元を保つため [] で囲む\n",
        "\n",
        "print('絞り込み後', x.shape)\n",
        "print(x[:5,:])\n",
        "\n",
        "# 正解データ yの表示\n",
        "print('正解データ')\n",
        "print(yt[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UG4aJY0YbHO7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "入力次元数: 1  出力次元数: 1\n"
          ]
        }
      ],
      "source": [
        "# 変数定義\n",
        "\n",
        "# 入力次元数\n",
        "n_input= x.shape[1]\n",
        "\n",
        "# 出力次元数\n",
        "n_output = 1\n",
        "\n",
        "print(f'入力次元数: {n_input}  出力次元数: {n_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qa_cV8urbs9s"
      },
      "outputs": [],
      "source": [
        "# 機械学習モデル（予測モデル）クラス定義\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        #  親クラスnn.Modulesの初期化呼び出し\n",
        "        super().__init__()\n",
        "\n",
        "        # 出力層の定義\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "\n",
        "        # 初期値を全部1にする\n",
        "        # 「ディープラーニングの数学」と条件を合わせる目的\n",
        "        nn.init.constant_(self.l1.weight, 1.0)\n",
        "        nn.init.constant_(self.l1.bias, 1.0)\n",
        "\n",
        "    # 予測関数の定義\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x) # 線形回帰\n",
        "        return x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wQ4TtPGQkWql"
      },
      "outputs": [],
      "source": [
        "# インスタンスの生成\n",
        "# １入力1出力の線形モデル\n",
        "\n",
        "net = Net(n_input, n_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bFf1N0HsXpCu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "変数名: l1.weight\n",
            "変数値: tensor([[1.]])\n",
            "変数名: l1.bias\n",
            "変数値: tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "# モデル内のパラメータの確認\n",
        "# モデル内の変数取得にはnamed_parameters関数を利用する\n",
        "# 結果の第1要素が名前、第2要素が値\n",
        "#\n",
        "# predict.weightとpredict.biasがあることがわかる\n",
        "# 初期値はどちらも1.0になっている\n",
        "\n",
        "for parameter in net.named_parameters():\n",
        "    print(f'変数名: {parameter[0]}')\n",
        "    print(f'変数値: {parameter[1].data}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RjHjfAf7XpCu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# パラメータのリスト取得にはparameters関数を利用する\n",
        "\n",
        "for parameter in net.parameters():\n",
        "    print(parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_zaPgb2td6vV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uWXVbu0leJgB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [1]                       --\n",
              "├─Linear: 1-1                            [1]                       2\n",
              "==========================================================================================\n",
              "Total params: 2\n",
              "Trainable params: 2\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(net, (1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "損失関数と最適化関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_-8Dq5hWfeoB"
      },
      "outputs": [],
      "source": [
        "# 損失関数： 平均2乗誤差\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "勾配降下法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-hiUPe-uXpCw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([506, 1])\n",
            "torch.Size([506])\n"
          ]
        }
      ],
      "source": [
        "# 入力変数x と正解値 ytのテンソル変数化\n",
        "\n",
        "inputs = torch.tensor(x).float()\n",
        "labels = torch.tensor(yt).float()\n",
        "\n",
        "# 次元数確認\n",
        "\n",
        "print(inputs.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0iRTGvM4XpCw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([506, 1])\n"
          ]
        }
      ],
      "source": [
        "# 損失値計算用にlabels変数を(N,1)次元の行列に変換する\n",
        "\n",
        "labels1 = labels.view((-1, 1))\n",
        "\n",
        "# 次元数確認\n",
        "print(labels1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "foVlKfQ5XpCw"
      },
      "outputs": [],
      "source": [
        "# 予測計算\n",
        "\n",
        "outputs = net(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "frF6g1MhXpCx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "308.44986\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#  損失計算\n",
        "loss = criterion(outputs, labels1)\n",
        "\n",
        "# 損失値の取得\n",
        "print(f'{loss.item():.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "j6IUY2obXpCx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-199.6421]])\n",
            "tensor([-30.4963])\n"
          ]
        }
      ],
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "#  損失計算\n",
        "loss = criterion(outputs, labels1)\n",
        "\n",
        "# 勾配計算\n",
        "loss.backward()\n",
        "\n",
        "# 勾配の結果が取得可能に\n",
        "print(net.l1.weight.grad)\n",
        "print(net.l1.bias.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SMwYMMXAXpCy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[2.9964]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.3050], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# パラメータ修正\n",
        "optimizer.step()\n",
        "\n",
        "# パラメータ値が変わる\n",
        "print(net.l1.weight)\n",
        "print(net.l1.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4SMBbG19XpCy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 勾配値の初期化\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# 勾配値がすべてゼロになっている\n",
        "print(net.l1.weight.grad)\n",
        "print(net.l1.bias.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "繰り返し計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "s6sIrMqiXpCy"
      },
      "outputs": [],
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# インスタンス生成　(パラメータ値初期化)\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 平均2乗誤差\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 50000\n",
        "\n",
        "# 評価結果記録用 (損失関数値のみ記録)\n",
        "history = np.zeros((0,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7Db7l67DeT9-",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 loss: 154.22493\n",
            "Epoch 100 loss: 29.61752\n",
            "Epoch 200 loss: 29.43177\n",
            "Epoch 300 loss: 29.25043\n",
            "Epoch 400 loss: 29.07340\n",
            "Epoch 500 loss: 28.90057\n",
            "Epoch 600 loss: 28.73186\n",
            "Epoch 700 loss: 28.56716\n",
            "Epoch 800 loss: 28.40636\n",
            "Epoch 900 loss: 28.24939\n",
            "Epoch 1000 loss: 28.09615\n",
            "Epoch 1100 loss: 27.94654\n",
            "Epoch 1200 loss: 27.80050\n",
            "Epoch 1300 loss: 27.65792\n",
            "Epoch 1400 loss: 27.51873\n",
            "Epoch 1500 loss: 27.38285\n",
            "Epoch 1600 loss: 27.25020\n",
            "Epoch 1700 loss: 27.12070\n",
            "Epoch 1800 loss: 26.99428\n",
            "Epoch 1900 loss: 26.87086\n",
            "Epoch 2000 loss: 26.75037\n",
            "Epoch 2100 loss: 26.63275\n",
            "Epoch 2200 loss: 26.51792\n",
            "Epoch 2300 loss: 26.40582\n",
            "Epoch 2400 loss: 26.29639\n",
            "Epoch 2500 loss: 26.18955\n",
            "Epoch 2600 loss: 26.08525\n",
            "Epoch 2700 loss: 25.98343\n",
            "Epoch 2800 loss: 25.88404\n",
            "Epoch 2900 loss: 25.78700\n",
            "Epoch 3000 loss: 25.69226\n",
            "Epoch 3100 loss: 25.59978\n",
            "Epoch 3200 loss: 25.50950\n",
            "Epoch 3300 loss: 25.42136\n",
            "Epoch 3400 loss: 25.33532\n",
            "Epoch 3500 loss: 25.25132\n",
            "Epoch 3600 loss: 25.16932\n",
            "Epoch 3700 loss: 25.08926\n",
            "Epoch 3800 loss: 25.01111\n",
            "Epoch 3900 loss: 24.93482\n",
            "Epoch 4000 loss: 24.86034\n",
            "Epoch 4100 loss: 24.78762\n",
            "Epoch 4200 loss: 24.71664\n",
            "Epoch 4300 loss: 24.64734\n",
            "Epoch 4400 loss: 24.57969\n",
            "Epoch 4500 loss: 24.51365\n",
            "Epoch 4600 loss: 24.44917\n",
            "Epoch 4700 loss: 24.38623\n",
            "Epoch 4800 loss: 24.32478\n",
            "Epoch 4900 loss: 24.26480\n",
            "Epoch 5000 loss: 24.20624\n",
            "Epoch 5100 loss: 24.14907\n",
            "Epoch 5200 loss: 24.09326\n",
            "Epoch 5300 loss: 24.03877\n",
            "Epoch 5400 loss: 23.98558\n",
            "Epoch 5500 loss: 23.93365\n",
            "Epoch 5600 loss: 23.88296\n",
            "Epoch 5700 loss: 23.83347\n",
            "Epoch 5800 loss: 23.78516\n",
            "Epoch 5900 loss: 23.73800\n",
            "Epoch 6000 loss: 23.69196\n",
            "Epoch 6100 loss: 23.64701\n",
            "Epoch 6200 loss: 23.60312\n",
            "Epoch 6300 loss: 23.56029\n",
            "Epoch 6400 loss: 23.51847\n",
            "Epoch 6500 loss: 23.47764\n",
            "Epoch 6600 loss: 23.43778\n",
            "Epoch 6700 loss: 23.39887\n",
            "Epoch 6800 loss: 23.36088\n",
            "Epoch 6900 loss: 23.32380\n",
            "Epoch 7000 loss: 23.28760\n",
            "Epoch 7100 loss: 23.25226\n",
            "Epoch 7200 loss: 23.21776\n",
            "Epoch 7300 loss: 23.18408\n",
            "Epoch 7400 loss: 23.15120\n",
            "Epoch 7500 loss: 23.11910\n",
            "Epoch 7600 loss: 23.08776\n",
            "Epoch 7700 loss: 23.05717\n",
            "Epoch 7800 loss: 23.02730\n",
            "Epoch 7900 loss: 22.99814\n",
            "Epoch 8000 loss: 22.96968\n",
            "Epoch 8100 loss: 22.94190\n",
            "Epoch 8200 loss: 22.91477\n",
            "Epoch 8300 loss: 22.88828\n",
            "Epoch 8400 loss: 22.86243\n",
            "Epoch 8500 loss: 22.83719\n",
            "Epoch 8600 loss: 22.81255\n",
            "Epoch 8700 loss: 22.78850\n",
            "Epoch 8800 loss: 22.76502\n",
            "Epoch 8900 loss: 22.74209\n",
            "Epoch 9000 loss: 22.71972\n",
            "Epoch 9100 loss: 22.69787\n",
            "Epoch 9200 loss: 22.67654\n",
            "Epoch 9300 loss: 22.65572\n",
            "Epoch 9400 loss: 22.63539\n",
            "Epoch 9500 loss: 22.61555\n",
            "Epoch 9600 loss: 22.59618\n",
            "Epoch 9700 loss: 22.57727\n",
            "Epoch 9800 loss: 22.55880\n",
            "Epoch 9900 loss: 22.54078\n",
            "Epoch 10000 loss: 22.52318\n",
            "Epoch 10100 loss: 22.50601\n",
            "Epoch 10200 loss: 22.48924\n",
            "Epoch 10300 loss: 22.47287\n",
            "Epoch 10400 loss: 22.45688\n",
            "Epoch 10500 loss: 22.44128\n",
            "Epoch 10600 loss: 22.42605\n",
            "Epoch 10700 loss: 22.41118\n",
            "Epoch 10800 loss: 22.39667\n",
            "Epoch 10900 loss: 22.38249\n",
            "Epoch 11000 loss: 22.36866\n",
            "Epoch 11100 loss: 22.35515\n",
            "Epoch 11200 loss: 22.34197\n",
            "Epoch 11300 loss: 22.32910\n",
            "Epoch 11400 loss: 22.31653\n",
            "Epoch 11500 loss: 22.30426\n",
            "Epoch 11600 loss: 22.29229\n",
            "Epoch 11700 loss: 22.28060\n",
            "Epoch 11800 loss: 22.26919\n",
            "Epoch 11900 loss: 22.25804\n",
            "Epoch 12000 loss: 22.24717\n",
            "Epoch 12100 loss: 22.23655\n",
            "Epoch 12200 loss: 22.22618\n",
            "Epoch 12300 loss: 22.21606\n",
            "Epoch 12400 loss: 22.20618\n",
            "Epoch 12500 loss: 22.19654\n",
            "Epoch 12600 loss: 22.18712\n",
            "Epoch 12700 loss: 22.17793\n",
            "Epoch 12800 loss: 22.16896\n",
            "Epoch 12900 loss: 22.16020\n",
            "Epoch 13000 loss: 22.15165\n",
            "Epoch 13100 loss: 22.14330\n",
            "Epoch 13200 loss: 22.13514\n",
            "Epoch 13300 loss: 22.12719\n",
            "Epoch 13400 loss: 22.11942\n",
            "Epoch 13500 loss: 22.11184\n",
            "Epoch 13600 loss: 22.10443\n",
            "Epoch 13700 loss: 22.09720\n",
            "Epoch 13800 loss: 22.09015\n",
            "Epoch 13900 loss: 22.08326\n",
            "Epoch 14000 loss: 22.07654\n",
            "Epoch 14100 loss: 22.06997\n",
            "Epoch 14200 loss: 22.06357\n",
            "Epoch 14300 loss: 22.05731\n",
            "Epoch 14400 loss: 22.05120\n",
            "Epoch 14500 loss: 22.04524\n",
            "Epoch 14600 loss: 22.03942\n",
            "Epoch 14700 loss: 22.03374\n",
            "Epoch 14800 loss: 22.02819\n",
            "Epoch 14900 loss: 22.02277\n",
            "Epoch 15000 loss: 22.01749\n",
            "Epoch 15100 loss: 22.01233\n",
            "Epoch 15200 loss: 22.00729\n",
            "Epoch 15300 loss: 22.00237\n",
            "Epoch 15400 loss: 21.99757\n",
            "Epoch 15500 loss: 21.99288\n",
            "Epoch 15600 loss: 21.98830\n",
            "Epoch 15700 loss: 21.98384\n",
            "Epoch 15800 loss: 21.97948\n",
            "Epoch 15900 loss: 21.97521\n",
            "Epoch 16000 loss: 21.97106\n",
            "Epoch 16100 loss: 21.96700\n",
            "Epoch 16200 loss: 21.96304\n",
            "Epoch 16300 loss: 21.95917\n",
            "Epoch 16400 loss: 21.95539\n",
            "Epoch 16500 loss: 21.95171\n",
            "Epoch 16600 loss: 21.94811\n",
            "Epoch 16700 loss: 21.94460\n",
            "Epoch 16800 loss: 21.94117\n",
            "Epoch 16900 loss: 21.93782\n",
            "Epoch 17000 loss: 21.93456\n",
            "Epoch 17100 loss: 21.93136\n",
            "Epoch 17200 loss: 21.92825\n",
            "Epoch 17300 loss: 21.92521\n",
            "Epoch 17400 loss: 21.92224\n",
            "Epoch 17500 loss: 21.91934\n",
            "Epoch 17600 loss: 21.91651\n",
            "Epoch 17700 loss: 21.91375\n",
            "Epoch 17800 loss: 21.91106\n",
            "Epoch 17900 loss: 21.90842\n",
            "Epoch 18000 loss: 21.90585\n",
            "Epoch 18100 loss: 21.90334\n",
            "Epoch 18200 loss: 21.90090\n",
            "Epoch 18300 loss: 21.89850\n",
            "Epoch 18400 loss: 21.89617\n",
            "Epoch 18500 loss: 21.89389\n",
            "Epoch 18600 loss: 21.89167\n",
            "Epoch 18700 loss: 21.88950\n",
            "Epoch 18800 loss: 21.88738\n",
            "Epoch 18900 loss: 21.88531\n",
            "Epoch 19000 loss: 21.88329\n",
            "Epoch 19100 loss: 21.88132\n",
            "Epoch 19200 loss: 21.87939\n",
            "Epoch 19300 loss: 21.87751\n",
            "Epoch 19400 loss: 21.87567\n",
            "Epoch 19500 loss: 21.87388\n",
            "Epoch 19600 loss: 21.87213\n",
            "Epoch 19700 loss: 21.87043\n",
            "Epoch 19800 loss: 21.86876\n",
            "Epoch 19900 loss: 21.86713\n",
            "Epoch 20000 loss: 21.86554\n",
            "Epoch 20100 loss: 21.86399\n",
            "Epoch 20200 loss: 21.86248\n",
            "Epoch 20300 loss: 21.86100\n",
            "Epoch 20400 loss: 21.85956\n",
            "Epoch 20500 loss: 21.85815\n",
            "Epoch 20600 loss: 21.85677\n",
            "Epoch 20700 loss: 21.85543\n",
            "Epoch 20800 loss: 21.85412\n",
            "Epoch 20900 loss: 21.85284\n",
            "Epoch 21000 loss: 21.85159\n",
            "Epoch 21100 loss: 21.85038\n",
            "Epoch 21200 loss: 21.84918\n",
            "Epoch 21300 loss: 21.84802\n",
            "Epoch 21400 loss: 21.84689\n",
            "Epoch 21500 loss: 21.84578\n",
            "Epoch 21600 loss: 21.84470\n",
            "Epoch 21700 loss: 21.84364\n",
            "Epoch 21800 loss: 21.84261\n",
            "Epoch 21900 loss: 21.84160\n",
            "Epoch 22000 loss: 21.84063\n",
            "Epoch 22100 loss: 21.83967\n",
            "Epoch 22200 loss: 21.83873\n",
            "Epoch 22300 loss: 21.83782\n",
            "Epoch 22400 loss: 21.83693\n",
            "Epoch 22500 loss: 21.83605\n",
            "Epoch 22600 loss: 21.83520\n",
            "Epoch 22700 loss: 21.83437\n",
            "Epoch 22800 loss: 21.83356\n",
            "Epoch 22900 loss: 21.83278\n",
            "Epoch 23000 loss: 21.83200\n",
            "Epoch 23100 loss: 21.83125\n",
            "Epoch 23200 loss: 21.83051\n",
            "Epoch 23300 loss: 21.82980\n",
            "Epoch 23400 loss: 21.82909\n",
            "Epoch 23500 loss: 21.82841\n",
            "Epoch 23600 loss: 21.82774\n",
            "Epoch 23700 loss: 21.82709\n",
            "Epoch 23800 loss: 21.82645\n",
            "Epoch 23900 loss: 21.82583\n",
            "Epoch 24000 loss: 21.82522\n",
            "Epoch 24100 loss: 21.82463\n",
            "Epoch 24200 loss: 21.82405\n",
            "Epoch 24300 loss: 21.82348\n",
            "Epoch 24400 loss: 21.82293\n",
            "Epoch 24500 loss: 21.82239\n",
            "Epoch 24600 loss: 21.82187\n",
            "Epoch 24700 loss: 21.82136\n",
            "Epoch 24800 loss: 21.82085\n",
            "Epoch 24900 loss: 21.82037\n",
            "Epoch 25000 loss: 21.81989\n",
            "Epoch 25100 loss: 21.81942\n",
            "Epoch 25200 loss: 21.81897\n",
            "Epoch 25300 loss: 21.81853\n",
            "Epoch 25400 loss: 21.81809\n",
            "Epoch 25500 loss: 21.81767\n",
            "Epoch 25600 loss: 21.81726\n",
            "Epoch 25700 loss: 21.81685\n",
            "Epoch 25800 loss: 21.81646\n",
            "Epoch 25900 loss: 21.81607\n",
            "Epoch 26000 loss: 21.81570\n",
            "Epoch 26100 loss: 21.81533\n",
            "Epoch 26200 loss: 21.81497\n",
            "Epoch 26300 loss: 21.81462\n",
            "Epoch 26400 loss: 21.81428\n",
            "Epoch 26500 loss: 21.81395\n",
            "Epoch 26600 loss: 21.81363\n",
            "Epoch 26700 loss: 21.81331\n",
            "Epoch 26800 loss: 21.81300\n",
            "Epoch 26900 loss: 21.81269\n",
            "Epoch 27000 loss: 21.81240\n",
            "Epoch 27100 loss: 21.81211\n",
            "Epoch 27200 loss: 21.81183\n",
            "Epoch 27300 loss: 21.81156\n",
            "Epoch 27400 loss: 21.81129\n",
            "Epoch 27500 loss: 21.81103\n",
            "Epoch 27600 loss: 21.81077\n",
            "Epoch 27700 loss: 21.81052\n",
            "Epoch 27800 loss: 21.81028\n",
            "Epoch 27900 loss: 21.81004\n",
            "Epoch 28000 loss: 21.80981\n",
            "Epoch 28100 loss: 21.80959\n",
            "Epoch 28200 loss: 21.80936\n",
            "Epoch 28300 loss: 21.80915\n",
            "Epoch 28400 loss: 21.80894\n",
            "Epoch 28500 loss: 21.80873\n",
            "Epoch 28600 loss: 21.80853\n",
            "Epoch 28700 loss: 21.80833\n",
            "Epoch 28800 loss: 21.80814\n",
            "Epoch 28900 loss: 21.80795\n",
            "Epoch 29000 loss: 21.80777\n",
            "Epoch 29100 loss: 21.80759\n",
            "Epoch 29200 loss: 21.80742\n",
            "Epoch 29300 loss: 21.80725\n",
            "Epoch 29400 loss: 21.80709\n",
            "Epoch 29500 loss: 21.80693\n",
            "Epoch 29600 loss: 21.80676\n",
            "Epoch 29700 loss: 21.80661\n",
            "Epoch 29800 loss: 21.80646\n",
            "Epoch 29900 loss: 21.80631\n",
            "Epoch 30000 loss: 21.80617\n",
            "Epoch 30100 loss: 21.80603\n",
            "Epoch 30200 loss: 21.80589\n",
            "Epoch 30300 loss: 21.80576\n",
            "Epoch 30400 loss: 21.80563\n",
            "Epoch 30500 loss: 21.80551\n",
            "Epoch 30600 loss: 21.80538\n",
            "Epoch 30700 loss: 21.80526\n",
            "Epoch 30800 loss: 21.80514\n",
            "Epoch 30900 loss: 21.80503\n",
            "Epoch 31000 loss: 21.80491\n",
            "Epoch 31100 loss: 21.80480\n",
            "Epoch 31200 loss: 21.80469\n",
            "Epoch 31300 loss: 21.80459\n",
            "Epoch 31400 loss: 21.80449\n",
            "Epoch 31500 loss: 21.80439\n",
            "Epoch 31600 loss: 21.80429\n",
            "Epoch 31700 loss: 21.80419\n",
            "Epoch 31800 loss: 21.80410\n",
            "Epoch 31900 loss: 21.80401\n",
            "Epoch 32000 loss: 21.80392\n",
            "Epoch 32100 loss: 21.80384\n",
            "Epoch 32200 loss: 21.80375\n",
            "Epoch 32300 loss: 21.80367\n",
            "Epoch 32400 loss: 21.80359\n",
            "Epoch 32500 loss: 21.80351\n",
            "Epoch 32600 loss: 21.80343\n",
            "Epoch 32700 loss: 21.80336\n",
            "Epoch 32800 loss: 21.80328\n",
            "Epoch 32900 loss: 21.80321\n",
            "Epoch 33000 loss: 21.80314\n",
            "Epoch 33100 loss: 21.80307\n",
            "Epoch 33200 loss: 21.80301\n",
            "Epoch 33300 loss: 21.80294\n",
            "Epoch 33400 loss: 21.80288\n",
            "Epoch 33500 loss: 21.80281\n",
            "Epoch 33600 loss: 21.80276\n",
            "Epoch 33700 loss: 21.80270\n",
            "Epoch 33800 loss: 21.80264\n",
            "Epoch 33900 loss: 21.80258\n",
            "Epoch 34000 loss: 21.80253\n",
            "Epoch 34100 loss: 21.80247\n",
            "Epoch 34200 loss: 21.80242\n",
            "Epoch 34300 loss: 21.80237\n",
            "Epoch 34400 loss: 21.80232\n",
            "Epoch 34500 loss: 21.80227\n",
            "Epoch 34600 loss: 21.80223\n",
            "Epoch 34700 loss: 21.80218\n",
            "Epoch 34800 loss: 21.80214\n",
            "Epoch 34900 loss: 21.80209\n",
            "Epoch 35000 loss: 21.80205\n",
            "Epoch 35100 loss: 21.80201\n",
            "Epoch 35200 loss: 21.80196\n",
            "Epoch 35300 loss: 21.80192\n",
            "Epoch 35400 loss: 21.80189\n",
            "Epoch 35500 loss: 21.80185\n",
            "Epoch 35600 loss: 21.80181\n",
            "Epoch 35700 loss: 21.80177\n",
            "Epoch 35800 loss: 21.80174\n",
            "Epoch 35900 loss: 21.80170\n",
            "Epoch 36000 loss: 21.80167\n",
            "Epoch 36100 loss: 21.80164\n",
            "Epoch 36200 loss: 21.80161\n",
            "Epoch 36300 loss: 21.80157\n",
            "Epoch 36400 loss: 21.80154\n",
            "Epoch 36500 loss: 21.80151\n",
            "Epoch 36600 loss: 21.80148\n",
            "Epoch 36700 loss: 21.80145\n",
            "Epoch 36800 loss: 21.80143\n",
            "Epoch 36900 loss: 21.80140\n",
            "Epoch 37000 loss: 21.80137\n",
            "Epoch 37100 loss: 21.80135\n",
            "Epoch 37200 loss: 21.80132\n",
            "Epoch 37300 loss: 21.80129\n",
            "Epoch 37400 loss: 21.80127\n",
            "Epoch 37500 loss: 21.80125\n",
            "Epoch 37600 loss: 21.80122\n",
            "Epoch 37700 loss: 21.80120\n",
            "Epoch 37800 loss: 21.80118\n",
            "Epoch 37900 loss: 21.80116\n",
            "Epoch 38000 loss: 21.80114\n",
            "Epoch 38100 loss: 21.80112\n",
            "Epoch 38200 loss: 21.80110\n",
            "Epoch 38300 loss: 21.80108\n",
            "Epoch 38400 loss: 21.80106\n",
            "Epoch 38500 loss: 21.80104\n",
            "Epoch 38600 loss: 21.80102\n",
            "Epoch 38700 loss: 21.80100\n",
            "Epoch 38800 loss: 21.80099\n",
            "Epoch 38900 loss: 21.80097\n",
            "Epoch 39000 loss: 21.80095\n",
            "Epoch 39100 loss: 21.80094\n",
            "Epoch 39200 loss: 21.80092\n",
            "Epoch 39300 loss: 21.80091\n",
            "Epoch 39400 loss: 21.80089\n",
            "Epoch 39500 loss: 21.80088\n",
            "Epoch 39600 loss: 21.80086\n",
            "Epoch 39700 loss: 21.80085\n",
            "Epoch 39800 loss: 21.80083\n",
            "Epoch 39900 loss: 21.80082\n",
            "Epoch 40000 loss: 21.80081\n",
            "Epoch 40100 loss: 21.80080\n",
            "Epoch 40200 loss: 21.80079\n",
            "Epoch 40300 loss: 21.80077\n",
            "Epoch 40400 loss: 21.80076\n",
            "Epoch 40500 loss: 21.80075\n",
            "Epoch 40600 loss: 21.80074\n",
            "Epoch 40700 loss: 21.80072\n",
            "Epoch 40800 loss: 21.80072\n",
            "Epoch 40900 loss: 21.80070\n",
            "Epoch 41000 loss: 21.80070\n",
            "Epoch 41100 loss: 21.80068\n",
            "Epoch 41200 loss: 21.80068\n",
            "Epoch 41300 loss: 21.80067\n",
            "Epoch 41400 loss: 21.80065\n",
            "Epoch 41500 loss: 21.80065\n",
            "Epoch 41600 loss: 21.80064\n",
            "Epoch 41700 loss: 21.80063\n",
            "Epoch 41800 loss: 21.80062\n",
            "Epoch 41900 loss: 21.80061\n",
            "Epoch 42000 loss: 21.80061\n",
            "Epoch 42100 loss: 21.80060\n",
            "Epoch 42200 loss: 21.80059\n",
            "Epoch 42300 loss: 21.80058\n",
            "Epoch 42400 loss: 21.80058\n",
            "Epoch 42500 loss: 21.80057\n",
            "Epoch 42600 loss: 21.80056\n",
            "Epoch 42700 loss: 21.80055\n",
            "Epoch 42800 loss: 21.80055\n",
            "Epoch 42900 loss: 21.80054\n",
            "Epoch 43000 loss: 21.80054\n",
            "Epoch 43100 loss: 21.80053\n",
            "Epoch 43200 loss: 21.80052\n",
            "Epoch 43300 loss: 21.80052\n",
            "Epoch 43400 loss: 21.80051\n",
            "Epoch 43500 loss: 21.80051\n",
            "Epoch 43600 loss: 21.80050\n",
            "Epoch 43700 loss: 21.80050\n",
            "Epoch 43800 loss: 21.80049\n",
            "Epoch 43900 loss: 21.80048\n",
            "Epoch 44000 loss: 21.80048\n",
            "Epoch 44100 loss: 21.80048\n",
            "Epoch 44200 loss: 21.80047\n",
            "Epoch 44300 loss: 21.80046\n",
            "Epoch 44400 loss: 21.80046\n",
            "Epoch 44500 loss: 21.80046\n",
            "Epoch 44600 loss: 21.80045\n",
            "Epoch 44700 loss: 21.80045\n",
            "Epoch 44800 loss: 21.80045\n",
            "Epoch 44900 loss: 21.80044\n",
            "Epoch 45000 loss: 21.80044\n",
            "Epoch 45100 loss: 21.80043\n",
            "Epoch 45200 loss: 21.80043\n",
            "Epoch 45300 loss: 21.80043\n",
            "Epoch 45400 loss: 21.80042\n",
            "Epoch 45500 loss: 21.80042\n",
            "Epoch 45600 loss: 21.80042\n",
            "Epoch 45700 loss: 21.80041\n",
            "Epoch 45800 loss: 21.80041\n",
            "Epoch 45900 loss: 21.80041\n",
            "Epoch 46000 loss: 21.80040\n",
            "Epoch 46100 loss: 21.80040\n",
            "Epoch 46200 loss: 21.80040\n",
            "Epoch 46300 loss: 21.80039\n",
            "Epoch 46400 loss: 21.80039\n",
            "Epoch 46500 loss: 21.80039\n",
            "Epoch 46600 loss: 21.80039\n",
            "Epoch 46700 loss: 21.80038\n",
            "Epoch 46800 loss: 21.80038\n",
            "Epoch 46900 loss: 21.80038\n",
            "Epoch 47000 loss: 21.80038\n",
            "Epoch 47100 loss: 21.80037\n",
            "Epoch 47200 loss: 21.80037\n",
            "Epoch 47300 loss: 21.80037\n",
            "Epoch 47400 loss: 21.80037\n",
            "Epoch 47500 loss: 21.80036\n",
            "Epoch 47600 loss: 21.80036\n",
            "Epoch 47700 loss: 21.80036\n",
            "Epoch 47800 loss: 21.80036\n",
            "Epoch 47900 loss: 21.80035\n",
            "Epoch 48000 loss: 21.80035\n",
            "Epoch 48100 loss: 21.80035\n",
            "Epoch 48200 loss: 21.80035\n",
            "Epoch 48300 loss: 21.80035\n",
            "Epoch 48400 loss: 21.80035\n",
            "Epoch 48500 loss: 21.80034\n",
            "Epoch 48600 loss: 21.80034\n",
            "Epoch 48700 loss: 21.80034\n",
            "Epoch 48800 loss: 21.80034\n",
            "Epoch 48900 loss: 21.80034\n",
            "Epoch 49000 loss: 21.80034\n",
            "Epoch 49100 loss: 21.80034\n",
            "Epoch 49200 loss: 21.80033\n",
            "Epoch 49300 loss: 21.80033\n",
            "Epoch 49400 loss: 21.80033\n",
            "Epoch 49500 loss: 21.80033\n",
            "Epoch 49600 loss: 21.80033\n",
            "Epoch 49700 loss: 21.80033\n",
            "Epoch 49800 loss: 21.80033\n",
            "Epoch 49900 loss: 21.80033\n"
          ]
        }
      ],
      "source": [
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 勾配値初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    # 「ディープラーニングの数学」に合わせて2で割った値を損失とした\n",
        "    loss = criterion(outputs, labels1) / 2.0\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "\n",
        "    # パラメータ修正\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100回ごとに途中経過を記録する\n",
        "    if ( epoch % 100 == 0):\n",
        "        history = np.vstack((history, np.array([epoch, loss.item()])))\n",
        "        print(f'Epoch {epoch} loss: {loss.item():.5f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
